\documentclass[10pt, oneside]{article}
\usepackage{amsmath, amsthm, amssymb, calrsfs, wasysym, verbatim, bbm, color, graphics, geometry}

\geometry{tmargin=.75in, bmargin=.75in, lmargin=.75in, rmargin = .75in}

\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Cdot}{\boldsymbol{\cdot}}

\newtheorem{thm}{Theorem}
\newtheorem{defn}{Definition}
\newtheorem{conv}{Convention}
\newtheorem{rem}{Remark}
\newtheorem{lem}{Lemma}
\newtheorem{cor}{Corollary}


\title{MATE 5150: Elementary Matrix Operations and Systrems of Linear Equations}
\author{Alejandro Ouslan}
\date{Academic Year 2024-2025}

\begin{document}

\maketitle
\tableofcontents

\vspace{.25in}

\section{Elementary Matrix Operations and Elementary Matrices}

In this section, we difine the elementary operations that are used throughout the chapter. In subsequent sections, we use these
operations to obtrain simiple computational methods for determining the rank of a linear transformation and the solution of a
system of linear equations. There are two types of elementary operations -row operations and column operations. As we will see,
the row operations are more useful. They arise from the three operations that can be used to eliminate variables in a system of linear equations.

\subsection{Elementary Operations}
\begin{defn}
	Let $A$ be an $m \times n$ matrix. Any of the following three operations on the rows [columns] of $A$ is called an \textbf{elementary row [column] operation}:
	\begin{enumerate}
		\item interchanging any two rows [columns] of $A$;
		\item multiplying any row [column] of $A$ by a nonzero scalar;
		\item adding any scalar multiple of a row [column] of $A$ to another row [column] of $A$.
	\end{enumerate}
\end{defn}

Any of these three operations is called an \textbf{elementary operation}. Elementary operations are of \textbf{type 1}, \textbf{type 2}, or \textbf{type 3} depending on
wheather they are obtained by (1), (2), or (3) above.

\begin{defn}
	An $n \times n$ \textbf{elementary matrix} is a matrix obtained by performing an elementary operations on $I_n$. The elemetnary matrix is said to be of \textbf{type 1}, \textbf{type 2}, or \textbf{type 3}
	acording to wheather the elementary operation performed on $I_n$ is of type 1, type 2, or type 3.
\end{defn}

\subsubsection{Example Elementary Matrices}
Let
\[
	A = \begin{bmatrix} 1 & 2 & 3 \\ 1 & 1 & 1 \\ 1 & -1 & 1 \end{bmatrix} \quad ,
	B = \begin{bmatrix} 1 & 0 & 3 \\ 1 & -2 & 1 \\ 1 & -3 & 1 \end{bmatrix} \quad \text{and} \quad ,
	C = \begin{bmatrix} 1 & 0 & 0 \\ 0 & -2 & -2 \\ 1 & -3 & 1 \end{bmatrix}
\]

Find an elementary operation that transforms $A$ into $B$ and an elementary operation that transforms $B$ into $C$. By means of several additional operations, transform C into $I_3$.
\[
	\begin{split}
		AE = B \quad & \text{where} \quad E = \begin{bmatrix} 1 & -2 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix} \\
		EB = C \quad & \text{where} \quad E = \begin{bmatrix} 1 & 0 & 0 \\ -1 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix} \\
		E_1E_2E_3E_4 = I_3 \quad & \text{where} \quad E_1 = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ -1 & 0 & 1 \end{bmatrix} \quad ,
		\quad E_2 = \begin{bmatrix} 1 & 0 & 0 \\ 0 & -\frac{1}{2} & 0 \\ 0 & 0 & 1 \end{bmatrix} \quad ,
		\quad E_3 = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 3 & 1 \end{bmatrix} \quad , E_4 = \begin{bmatrix} 1 & 0 & 3 \\ 0 & 1 & 1 \\ 0 & 0 & 1 \end{bmatrix}
	\end{split}
\]

\subsection{Properties of Elementary Matrices}
\begin{thm}
	Elementary matrices are invertible, and the inverse of an elementary matrix is an elementary matrix of the same type.
\end{thm}

\begin{proof}
	\begin{align*}
		\intertext{Let $E$ be an elementary matrix $n \times n$. The $E$ is defided by an elementary operation on $I_n$.}
	\end{align*}
\end{proof}

\subsubsection{Example}
Use the proog in Theroem 1 to obtain the inverse of each of the folowing elementary matrices:
\[
	A = \begin{bmatrix} 0 & 0 & 1 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}, \quad
	B = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 3 & 0 \\ 0 & 0 & 1 \end{bmatrix}, \quad
	C = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ -2 & 0 & 1 \end{bmatrix}
\]
Finding the inverse of each of the elementary matrices in the example above, we have:
\[
	\begin{split}
		E &= \begin{bmatrix} 0 & 0 & 1 \\ 0 & 1 & 0 \\ 1 & 0 & 0 \end{bmatrix} \quad , \text{Therefore} \quad A^{-1} = \begin{bmatrix} 0 & 0 & 1 \\ 0 & 1 & 0 \\ 1 & 0 & 0 \end{bmatrix} \\
		E &= \begin{bmatrix} 1 & 0 & 0 \\ 0 & \frac{1}{3} & 0 \\ 0 & 0 & 1 \end{bmatrix} \quad , \text{Therefore} \quad B^{-1} = \begin{bmatrix} 1 & 0 & 0 \\ 0 & \frac{1}{3} & 0 \\ 0 & 0 & 1 \end{bmatrix} \\
		E &= \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 2 & 0 & 1 \end{bmatrix} \quad , \text{Therefore} \quad C^{-1} = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ -2 & 0 & 1 \end{bmatrix}
	\end{split}
\]

\subsection{Matrix Multiplication and Elementary Matrices}

Let $A$ be an $m \times n$ matrix. Prove that if $E$ can be otained from $A$ by an elementary row [column] operation, then $B^T$ can be obtained from $A^T$ by the corresponding elementary column [row] operation.

\begin{proof}
	\begin{align*}
		(E_RB)^T & = (A)^T \\
		B^TE_R^T & = A^T
	\end{align*}
	Therefore, $B^T$ can be obtained from $A^T$ by the corresponding elementary column operation.
\end{proof}

\section{The Rank of a Matrix and Matrix Inverses}

In this section, we define the \textit{rank} of a matrix. We then use lementary operations to compute the rank of a marix and a lineear transformation. The section concludes with
a procedure for compuing the inverse of an invertible matrix.

\begin{defn}
	If $A \in M_{m \times n(F)}$, We defin the \textbf{rank} of $A$, denoted $rank(A)$, to be the rank of the linear transformation $L_A: F^n \to F^m$.
\end{defn}

Every matrix $A$ is the matrix representation of the linear transformation $L_A$ with repect to the appropriate standard ordere bases. Thuse the rank of the linear tgransformation $L_A$
is the same as the rank of one of its matrrix representations, namely, $A$. The next theorem ectends this fact to aqny matrix representation of any linear transformation fedined on finite-dimensional
vector spaces.

\begin{thm}
	Let $T:V \to W$ be a linear transformation between finite dimensional vector spaces, and let $\beta$ and $\gamma$ be ordered bases for $V$ and $W$, respectively.
	Then $rank(T) = rank([T]_{\beta}^{\gamma})$.
\end{thm}

\begin{thm}
	Let $A$ be an $m \times n$ matrix. If $P$ and $Q$ are invertible matrices of sizes $m \times m$ and $n \times n$, respectively, then
	\begin{enumerate}
		\item $rank(AQ) = rank(A)$
		\item $rank(PA) = rank(A)$
		\item $rank(PAQ) = rank(A)$
	\end{enumerate}
\end{thm}

\begin{cor}
	Elemenary row and column operations on a matrix are rnak-preserving.
\end{cor}

Now that we have a class of matrix operations that perserve rank, we need a way of examining a transformed matrix to ascertain its rank. The next theorem
is the first of several in this direction.

\begin{thm}
	The rank of any matrix equals the maximum number of its linearly indipendcent columns; that is the rnaak of a matreix is the dimension of the subspace generated by its columns.
\end{thm}

\subsubsection{Example}
Find the rank of the following matrix:
\[
	A = \begin{bmatrix} 1 & 1 & 0 \\ 0 & 1 & 1 \\ 1 & 1 & 0 \end{bmatrix}, \quad B = \begin{bmatrix} 1 & 1 & 0 \\ 2 & 1 & 1 \\ 1 & 1 & 1 \end{bmatrix}
\]

\subsubsection{Example}
Prove that for any $m \times n$ matrix $A$, $rank(A) = 0$ if and only if $A$ is the zero matrix.

The next theorem uses this process to transform a matrix into a particularly simple form. The power of this theorem can be seen in its corallaries.

\begin{thm}
	Let $A$ be an $m \times n$ matrix of rank $r$. Then $r \leq m$ , $r \leq n$, and by means of a finit number of elementary row and column operations, $A$ can be transformed into the matrix
	\[
		D = \begin{bmatrix} I_r & O_1 \\ O_2 & O_3 \end{bmatrix}
	\]
	Where $O_1$, $O_2$, and $O_3$ are zero matrices. Thus $D_{ii} = 1$ for $1 \leq i \leq r$ and $D_{ij} = 0$ otherwise.
\end{thm}

\begin{cor}
	Let $A$ be an $m \times n$ matrix of rank $r$. Then there exist invertible matrices $B$ and $C$ of sizes $m \times m$ and $n \times n$, respectively, such that $D = BAC$, where
	\[
		D = \begin{bmatrix} I_r & O_1 \\ O_2 & O_3 \end{bmatrix}
	\]
	is the $m \times n$ matrix in which $O_1$, $O_2$, and $O_3$ are zero matrices.
\end{cor}

\begin{cor}
	Let $A$ be an $m \times n$ matrix. Then
	\begin{enumerate}
		\item $rank(A^T) = rank(A)$.
		\item The rank of any matrix equals the maximum number of its linearly independent rows; that is, the rank if a matrix is the dimension of the subspace generated by its rows.
		\item The rows and columns of  any matrix generate subspace of the same dimensions, numerically equal to the rank of the matrix.
	\end{enumerate}
\end{cor}

\begin{cor}
	Every invertible matrix is a product of elementary matrices.
\end{cor}

\begin{proof}
	\begin{align*}
		d
	\end{align*}
\end{proof}

\begin{thm}
	Let $T:V \to W$ and $U:W \to Z$ be linear transformations on finite-dimensional vector spaces $V$, $W$, and $Z$ and let $A$ and $B$ be matrices such that the product $AB$ is defined.
	Then
	\begin{enumerate}
		\item $rank(UT) \leq rank(U)$
		\item $rank(UT) \leq rank(T)$
		\item $rank(AB) \leq rank(A)$
		\item $rank(AB) \leq rank(B)$
	\end{enumerate}
\end{thm}

\subsubsection{Example}
Use elementary row and column operations to transform each of the following matrices into a matrix $D$ satisfying the condfitions of Theorem 5, and then detemine the rank of each matrix:
\[
	A = \begin{bmatrix} 1 & 1 & 1 & 2 \\ 2 & 0 & -1 & 2 \\ 1 & 1 & 1 & 2 \end{bmatrix} \quad , \quad B = \begin{bmatrix} 2 & 1 \\ -1 & 2 \\ 2 & 1 \end{bmatrix}
\]

\subsubsection{Example}
For each of the following linear transformation $T$, determine wheather $T$ is invertible, and compute $T^{-1}$ if it exists:

Let $T: \R^3 \to \R^3$ be defined by

\[
	T(a_1, a_2, a_3) = (a_1 + 2a_2 + a_3, -a_1 + a_2 + 2a_3, a_1 + a_3)
\]


\subsection{The inverse of a Matrix}
We have remarked that an $n \times n$ matrix is invertible if and only if its rank is $n$. Since we know how to compute the rank of any matrix, we can always test a matrix
to dermine wheather its is invertible, We now provide a simple techinque for computing the inverse of a matrix that utilizes elementrary row operations.

\begin{thm}
	Let $A$ and $B$ be $m \times n$ and $m \times p$ matrices, respectively. By the \textbf{augmented matrix} $[A|B]$, we mean the $m \times (n + p)$ matrix, that is, the matrix whose first $n$ columns are
	the columns of $A$, and whose last $p$ columns are the columns of $B$.
\end{thm}

Conversely, suppose that $A$ is invertible and that, for some $m \times p$ matrix $B$, the matrix $[A|I_n]$ can be transformed into the matrix $[I_n|B]$ by a finite number of elementary row operations.
Let $E_1, E_2, \ldots, E_p$ be the elementary matrices associated with these elementary row operations as in Theorem 1. Then


\subsubsection{Example}
Express the invertible matrix
\[
	A = \begin{bmatrix} 1 & 2 & 1 \\ 1 & 0 & 1 \\ 1 & 1 & 2 \end{bmatrix}
\]
As a product of elementary matrices.
\end{document}
