\documentclass[10pt, oneside]{article}
\usepackage{amsmath, amsthm, amssymb, calrsfs, wasysym, verbatim, bbm, color, graphics, geometry}

\geometry{tmargin=.75in, bmargin=.75in, lmargin=.75in, rmargin = .75in}

\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Cdot}{\boldsymbol{\cdot}}

\newtheorem{thm}{Theorem}
\newtheorem{defn}{Definition}
\newtheorem{conv}{Convention}
\newtheorem{rem}{Remark}
\newtheorem{lem}{Lemma}
\newtheorem{cor}{Corollary}


\title{MATE 5150: Determinants}
\author{Alejandro Ouslan}
\date{Academic Year 2024-2025}

\begin{document}

\maketitle
\tableofcontents

\vspace{.25in}

\section{Determinants of Order 2}

\section{Determinants of Order $n$}

\section{Properties of Determinants}

\subsection{Facts about elementary Matrices}

\begin{enumerate}
	\item If $E$ is an elementary matrix obtained by interchanging any two rows of $I_n$, then $\det(E) = -1$.
	\item If $E$ is an elementary matrix obtained by multiplying some row of $I_n$ by the nonzero scalar $K$, then $\det(E) = K$.
	\item If $E$ is an elementary matrix obtained by adding a multiple of some row of $I_n$ to another row, the $\det(E) = 1$.
\end{enumerate}

\begin{thm}
	For any $A,B \in M_{n \times n}(\R)$, $\det(AB) = \det(A)\cdot \det(B)$.
\end{thm}

\begin{proof}
	\begin{align*}
		\det(AB) & = \det(E_m \cdots E_2E_1B)                     \\
		         & = \det(E_m) \cdot \det(E_{m-1} \cdots E_2E_1B) \\
		         & = \det(E_m \cdots E_2E_1) \cdot \det(B)        \\
		         & = \det(A) \cdot \det(B)
	\end{align*}
	Therefore, $\det(AB) = \det(A)\det(B)$.
\end{proof}

\begin{cor}
	A Matrix $A \in M_{n \times n}(F)$ is invertible if and only if $\det(A) \neq 0$. Furthermore, if $A$ is invertible, then $\det(A^{-1}) = \frac{1}{\det(A)}$.
\end{cor}

\begin{proof}
	\begin{align*}
		\intertext{If $A$ is invertible, then $rank(A) < n$}
		\intertext{So by the Correlation 4.6, $\det(A) = 0$}
		\intertext{If $A$ is not invertible, then}
		\det(A) \cdot \det(A^{-1}) & = \det(AA^{-1}) = \det(I_n) = 1 \\
	\end{align*}
	Therefore, $\det(A^{-1}) = \frac{1}{\det(A)}$ if $A$ is invertible and $\det(A) \neq 0$.
\end{proof}

\begin{thm}
	For any $A \in M_{n \times n}(F)$, $\det(A^T) = \det(A)$.
\end{thm}

\begin{proof}
	\begin{align*}
		\det(A^T) & = \det(E_1^T \cdot E_2^T \cdots E_m^T)             \\
		          & = \det(E_1^T) \cdot \det(E_2^T) \cdots \det(E_m^T) \\
		          & = \det(E_1) \cdot \det(E_2) \cdots \det(E_m)       \\
		          & = \det(E_m \cdots E_2E_1)                          \\
		          & = \det(A)
	\end{align*}
	Therefore, $\det(A^T) = \det(A)$.
\end{proof}

\begin{thm}[Cramer's Rule]
	Let $Ax = b$ be the matrix form of a system of $n$ linear equations in $n$ unknowns. Where $x = (x_1, x_2, \ldots, x_n)^T$. If $\det(A) \neq 0$, then this system has a unique solution, and
	for each $k$ $(k = 1, 2, \ldots, n)$,
	$$ x_k = \frac{\det(M_k)}{\det(A)} $$
	where $M_k$ is the $n \times n$ matrix obtained from $A$ by replacing column $k$ of $A$ by $b$.
\end{thm}

\begin{proof}
	Let \( X_k \) be the matrix obtained from \( A \) by replacing the \( k \)-th column of \( A \) with the vector \( \mathbf{b} \). Then we can write the system as:

	\[
		A X_k = M_k
	\]

	where \( M_k \) is the vector formed by the coefficients of the system in the new configuration.

	To evaluate \( \det(X_k) \) using cofactor expansion along the \( k \)-th column, we have:

	\[
		\det(X_k) = x_k \det(I_{n-1})
	\]

	Since \( \det(I_{n-1}) = 1 \), it follows that:

	\[
		\det(X_k) = x_k
	\]

	By applying the property of determinants, we obtain:

	\[
		\det(M_k) = \det(A X_k) = \det(A) \cdot \det(X_k)
	\]

	Substituting \( \det(X_k) \) into this equation gives:

	\[
		\det(M_k) = \det(A) \cdot x_k
	\]

	Therefore, we can rearrange this to find \( x_k \):

	\[
		x_k = \frac{\det(M_k)}{\det(A)}
	\]

	This proves Cramer's Rule for the variable \( x_k \).
\end{proof}
\section{Summary - Important Facts about Determinants}

\end{document}
